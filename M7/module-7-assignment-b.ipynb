{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPCS56430 Assignment 7B\n",
    "\n",
    "# Problem 1. RCC Single Node Blast\n",
    "Using the RCC version of BLAST, conduct a single node run of the following sequence against the `refseq` database. The databases we will be using are located on a shared directory for the class located at `/project2/mpcs56430/db`. \n",
    "\n",
    "Query sequence:\n",
    "``` \n",
    ">YP_009724390.1 surface glycoprotein [Severe acute respiratory syndrome coronavirus 2]\n",
    "MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHV\n",
    "SGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPF\n",
    "LGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPI\n",
    "NLVRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYN\n",
    "ENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASV\n",
    "YAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIAD\n",
    "YNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYF\n",
    "PLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFL\n",
    "PFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQDVNCTEVPVAIHADQLT\n",
    "PTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSPRRARSVASQSIIAYTMSLG\n",
    "AENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGI\n",
    "AVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDC\n",
    "LGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIG\n",
    "VTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDI\n",
    "LSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLM\n",
    "SFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNT\n",
    "FVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVA\n",
    "KNLNESLIDLQELGKYEQYIKWPWYIWLGFIAGLIAIVMVTIMLCCMTSCCSCLKGCCSCGSCCKFDEDD\n",
    "SEPVLKGVKLHYT\n",
    "```\n",
    "\n",
    "Perform several runs and establish a baseline time for the database search. Please, run the job using `sinteractive` so it runs on worker node."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running times with 1 thread:**\n",
    "- 0.54s\n",
    "- 0.25s\n",
    "- 0.31s\n",
    "- 0.25s\n",
    "- 0.31s\n",
    "  \n",
    "avg: 0.332s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Does altering the `--num_threads` parameter change the runtime? Is this the same as what your observed running it locally?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 threads**:\n",
    "- 0.25s\n",
    "- 0.32s\n",
    "- 0.49s\n",
    "- 0.27s\n",
    "- 0.31s\n",
    "\n",
    "avg: 0.328s\n",
    "\n",
    "**4 threads**:\n",
    "- 0.28s\n",
    "- 0.26s\n",
    "- 0.25s\n",
    "- 0.25s\n",
    "- 0.26s\n",
    "\n",
    "avg: 0.26s\n",
    "\n",
    "**16 threads**:\n",
    "- 0.83s\n",
    "- 0.32s\n",
    "- 0.32s\n",
    "- 0.28s\n",
    "- 1.32s\n",
    "\n",
    "avg: 0.614s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the --num_threads parameter does not really change the runimes, they are all around 0.3s.\n",
    "Too many threads (like 16) actually worsens the running time, in this case doubling the average. This is most likely due to overhead."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Redo all the same runs, but this time using a RCC _big mem_ machine. Does this make a difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Threads Runtime (with big mem):\n",
    "> \n",
    "> 1 Thread: 0.25s\\\n",
    "> 2 Threads: 0.24s\\\n",
    "> 4 Threads: 1.35s\\\n",
    "> 6 Threads: 0.24s\\\n",
    "> 8 Threads: 0.24s\\\n",
    "> 16 Threads: 0.24s\\\n",
    "> 32 Threads: 0.24s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: \\\n",
    "The big mem machine does not have a significant inmpact on the total execution time, as the times stay arounf 0.25s which is not significantly faster than the runs shown previously. Running on 4 threads even performs significantly worse, though this may be a one-off error.\n",
    "\n",
    "Script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1217766901.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    module load blast\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "#BATCH --account=mpcs56430\n",
    "#SBATCH --mail-user=sharapova@cs.uchicago.edu\n",
    "#SBATCH --mail-type=ALL\n",
    "\n",
    "#SBATCH --job-name=b_problem1          # Job name\n",
    "#SBATCH --output=./sbatch/out/%j.B1.out\n",
    "#SBATCH --error=./sbatch/out/%j.B1.err\n",
    "#SBATCH --cpus-per-task=4          # Number of CPU cores per task\n",
    "#SBATCH --nodes=1                  # One node per task\n",
    "#SBATCH --partition=bigmem2\n",
    "#\n",
    "#\n",
    "\n",
    "\n",
    "# Load necessary modules (if required, e.g., BLAST+)\n",
    "module load blast\n",
    "\n",
    "# Paths to query and database\n",
    "QUERY=~/../../project2/mpcs56430/db/query_sequence.fasta\n",
    "DB_PATH=~/../../project2/mpcs56430/db/refseq # uh ohhh, inconsistent with part  b... might have been the cause of error...\n",
    "\n",
    "# Array of thread counts\n",
    "THREADS=(1 2 4 6 8 16 32)\n",
    "\n",
    "# Output file for times\n",
    "TIMES_FILE=\"blastp_times_bigmem.txt\"\n",
    "echo \"Threads Runtime\" > $TIMES_FILE\n",
    "\n",
    "# Loop through thread counts and run BLASTP\n",
    "for THREAD in \"${THREADS[@]}\"\n",
    "do\n",
    "    echo \"Running BLASTP with $THREAD threads...\"\n",
    "    OUTPUT_FILE=\"tmp_out/blastp_${THREAD}_threads.out\"\n",
    "    \n",
    "    # Run BLASTP and capture runtime\n",
    "    { time -p blastp -query $QUERY -db $DB_PATH -num_threads $THREAD -out $OUTPUT_FILE ; } 2> temp_time.txt\n",
    "    \n",
    "    # Extract runtime\n",
    "    RUNTIME=$(grep \"real\" temp_time.txt | awk '{print $2}')\n",
    "    \n",
    "    # Save thread count and runtime to file\n",
    "    echo \"$THREAD $RUNTIME\" >> $TIMES_FILE\n",
    "done\n",
    "\n",
    "# Cleanup\n",
    "rm temp_time.txt\n",
    "\n",
    "echo \"All BLASTP runs completed. Times saved in $TIMES_FILE.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NOTE: After re-running the script the next day, the numbers were very different and this is what you see in the blastp_times text files submitted._ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2. SLURM Array Job\n",
    "One of the simplest ways to parrallelize a computing task is to break it in to smaller parts.  Write a SLURM submission script that submits the above query against the fragmented *nr* database in *array job* mode.  \n",
    "\n",
    "The *nr* database has already been fragmented into 22 equally sized databases. It is located in the `db` diretory in the format: `/project2/mpcs56430/db/refseq_protein.[00-21]`.  \n",
    "\n",
    "You should create a single script that utilizes the SLURM *array job* functionality.  Specify only 1 task per node.  Paste your script below and include it in the assignment repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#BATCH --account=mpcs56430\n",
    "#SBATCH --mail-user=sharapova@cs.uchicago.edu\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --job-name=blastp_array          # Job name\n",
    "#SBATCH --output=./sbatch/out/bp_array_%j.out\n",
    "#SBATCH --error=./sbatch/out/bp_array_%j.err\n",
    "#SBATCH --cpus-per-task=16          # Number of CPU cores per task\n",
    "#SBATCH --nodes=1                  # One node per task\n",
    "#SBATCH --time=02:00:00\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --array=0-21\n",
    "#SBATCH --partition=bigmem2\n",
    "\n",
    "# Load BLAST module \n",
    "# module load blast\n",
    "# conda activate blast\n",
    "\n",
    "# Define the query file\n",
    "# QUERY=~/../../project2/mpcs56430/db/query_seq_b.fasta\n",
    "QUERY=~/../../project2/mpcs56430/db/query_sequence.fasta\n",
    "\n",
    "# Define the database prefix and fragment pattern\n",
    "DB_PREFIX=~/../../project2/mpcs56430/db/refseq_protein\n",
    "DB_FRAGMENT=${DB_PREFIX}.$(printf \"%02d\" $SLURM_ARRAY_TASK_ID)\n",
    "\n",
    "# Define the output directory and file\n",
    "OUTPUT_DIR=./assignment_b/array_output\n",
    "mkdir -p $OUTPUT_DIR\n",
    "OUTPUT_FILE=${OUTPUT_DIR}/blastp_${SLURM_ARRAY_TASK_ID}.out\n",
    "\n",
    "# Run BLASTP for the current database fragment\n",
    "echo \"Running BLASTP for database fragment $DB_FRAGMENT...\"\n",
    "time -p blastp -query $QUERY -db $DB_FRAGMENT -num_threads 16 -out $OUTPUT_FILE\n",
    "\n",
    "echo \"BLASTP for database fragment $DB_FRAGMENT completed.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outputs in assignment_b.out and sbatch/out**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What is the runtime for the entire job?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command used to find total times:\n",
    "> $ grep \"real\" ./sbatch/out/bp_array_43369*.err | awk '{sum += $2} END {print \"Total Runtime:\", sum, \"seconds\"}'\n",
    "\n",
    "Total Runtime: 45.29 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NOTE: most times were around 0.01 and 0.02, but some had a runtime of around 11s so this caused the total runtime to be skewed.. You can  see the times in sbatch/out/bp_array_43369*.err\\\n",
    "Some of the runs gave errors such as:_\n",
    "> _BLAST Database error: No alias or index file found for protein database [/home/sharapova/../../project2/mpcs56430/db/refseq_protein.19] in search path [/scratch/midway3/sharapova/mpcs56430-2024-autumn-assignment-7-s-sharapova:/project2/databases/blast:]_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3. HPC Speedup\n",
    "\n",
    "Speedup is a metric used to assess the relative performance improvement gained by executing one task versus another.  In our case, we are comparing serial execution (a single process) of searching a single sequence against a database versus a task parallelism version. \n",
    "\n",
    "Speedup is defined as \n",
    "$$ S \\equiv \\frac{T_{\\text{Old}}}{T_{\\text{New}}} $$ \n",
    "\n",
    "where $S$ is speedup, $T_{\\text{Old}}$ is the time taken to execute the script without improvement (serial), and $T_{\\text{New}}$ is the time taken to execute the script with the improvement (parallel).\n",
    "\n",
    "**Question:** What is the speedup of a single node job against in Problem 1 vs running as an array job in Problem 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$T_{Old} = 0.332s$\n",
    "\n",
    "$T_{New} = \\text{Total parallel runtime is the maximum runtime across all fragments} = 11.32..$\n",
    "\n",
    "$\\text{Speedup} = 0.332 / 11.32 = 0.029$\n",
    "\n",
    "Terrible and WRONG!! whoopsie.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But comparing num-thread parallelization we get:\n",
    "\n",
    "$\\text{Speedup} = 0.332 / 0.26 = 1.2769$\n",
    "\n",
    "but this is not thaaaat great.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Experiment with any other SLURM settings that you can think of (eg. _tasks per node_,) and identify what combination gives the best speedup for the query against the entire database? Support your answer with a benchmark experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approaches:**\n",
    "\n",
    "- Run the array job with different --cpus-per-task values (4, 8, 16): _this monitors how increased CPU utilization affects runtimes._\n",
    "- Using Multiple Nodes (--nodes): _this tests running the array job across multiple nodes (distributes tasks)_\n",
    "- Experiment with --ntasks and --ntasks-per-node "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My values did not change with these adjustments, but maybe running on a different set would work. I was having issues with the RCC.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
